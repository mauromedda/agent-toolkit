# ABOUTME: Detailed Gemini collaboration workflow and decision matrix
# ABOUTME: Referenced from CLAUDE.md for complete invocation guidelines

# Gemini Collaboration Workflow

This guide provides detailed instructions for when and how to invoke Gemini for second opinions during development.

## Philosophy

Gemini serves two roles:
1. **Design Partner** (BEFORE planning): Helps evaluate architectural options
2. **Code Reviewer** (AFTER implementation): Catches issues before commit

## Decision Matrix

### BEFORE Planning (Design Phase)

| Scenario | Example | Gemini Prompt Focus |
|----------|---------|---------------------|
| New feature | "Add user auth" | Architecture, patterns, trade-offs |
| System design change | "Add caching layer" | Integration strategy, consistency |
| Technology choice | "Which DB to use?" | Pros/cons, codebase fit |
| Pattern decision | "Event sourcing vs CRUD?" | Long-term implications |
| **Architectural review** | "Review dispatcher architecture" | Separation of concerns, counter-analysis |

**CRITICAL**: Architectural reviews that produce recommendations ARE design decisions. Call Gemini BEFORE presenting your analysis.

### AFTER Implementation (Review Phase)

| Scenario | Threshold | Gemini Prompt Focus |
|----------|-----------|---------------------|
| Code changes | >100 lines substantive | Correctness, edge cases |
| Multi-file changes | >3 files with logic | Integration, consistency |
| Security code | Any auth/crypto/input validation | Vulnerabilities, OWASP |
| Performance code | Critical path optimization | Async, memory, concurrency |

### Skip Gemini (Fast Path)

| Scenario | Why Skip |
|----------|----------|
| <100 lines, single file | Low risk, quick iteration |
| Formatting, imports | No logic change |
| Version bumps | Mechanical |
| Documentation only | No code impact |
| String constants | No behavior change |

## Timing Clarification

### "BEFORE Planning" Means:

```
User request
    â†“
Claude explores codebase (Glob, Grep, Read, Explore agent)
    â†“
Claude has findings and is ready to propose solutions
    â†“
â˜… CALL GEMINI HERE â˜…
    â†“
Claude presents options with Gemini's input
    â†“
User approves
    â†“
Claude implements
```

**Key insight:** Exploration is NOT planning. Call Gemini after you understand the codebase but before you present options.

## ðŸ”„ RESUMED SESSION CHECKPOINT

**When a session is resumed from context compaction, STOP and verify Gemini workflow state:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SESSION RESUMED - MANDATORY GEMINI VERIFICATION                â”‚
â”‚                                                                 â”‚
â”‚  Before continuing ANY work, answer these questions:            â”‚
â”‚                                                                 â”‚
â”‚  1. Was I in the middle of implementing code?                   â”‚
â”‚     â†’ Check the summary for "in progress" or "pending" tasks    â”‚
â”‚                                                                 â”‚
â”‚  2. How many files were modified before compaction?             â”‚
â”‚     â†’ Run: git diff --stat                                      â”‚
â”‚                                                                 â”‚
â”‚  3. Did I already call Gemini for review?                       â”‚
â”‚     â†’ Search summary for "gemini" or "code review"              â”‚
â”‚                                                                 â”‚
â”‚  If implementation was in progress AND Gemini wasn't called:    â”‚
â”‚  â†’ CALL GEMINI FIRST before continuing implementation           â”‚
â”‚                                                                 â”‚
â”‚  If implementation is complete but tests weren't run:           â”‚
â”‚  â†’ Check thresholds (>100 lines OR >3 files) â†’ Call Gemini      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### "AFTER Implementation" Means:

```
User approves approach
    â†“
Claude implements (TDD: Red â†’ Green â†’ Refactor)
    â†“
Claude is ready to commit
    â†“
â˜… CALL GEMINI HERE (if threshold met) â˜…
    â†“
Claude addresses Gemini feedback
    â†“
Claude commits
```

## Invocation Syntax

### Basic Format

```bash
gemini -m gemini-3-pro-preview "PROMPT" .
```

### Bash Tool Parameters

```
timeout: 1800000  # 30 minutes - complex analysis needs time
```

### Common Mistakes

| Mistake | Correct |
|---------|---------|
| Running in background | Wait synchronously |
| Forgetting `.` path | Always include `.` |
| Timeout too short | Use 1800000 (30 min) |
| Copying file contents | Describe goal, let Gemini explore |

## Prompt Templates

### Design Review

```
I need to implement [FEATURE DESCRIPTION].

Current codebase context:
- [Key architectural patterns observed]
- [Relevant existing components]

Questions:
1. Where should this logic live?
2. What patterns fit best?
3. What are the trade-offs between approaches?

Please propose 2-3 alternatives with pros/cons.
```

### Architectural Analysis Review

Use BEFORE presenting architectural review findings:

```
I've analyzed [COMPONENT] architecture and found:

Key observations:
- [FINDING 1]
- [FINDING 2]
- [FINDING 3]

I'm about to recommend:
- [RECOMMENDATION 1]
- [RECOMMENDATION 2]

Counter-analyze:
1. What issues am I missing?
2. Are my recommendations sound?
3. What alternative approaches exist?
4. What are the trade-offs I haven't considered?

Provide a counter-analysis before I present to the user.
```

### Code Review

```
Review my recent changes for [COMPONENT/FEATURE].

Focus areas:
- Correctness and edge cases
- Error handling
- [Specific concerns]

The changes are in: [list key files or describe scope]
```

### Security Review

```
Security review for [COMPONENT].

Check for:
- Authentication/authorization issues
- Input validation gaps
- Token/session handling
- OWASP top 10 vulnerabilities
- Sensitive data exposure

The security-relevant code is in: [list files]
```

### Performance Review

```
Performance review for [OPTIMIZATION].

Check for:
- Async/await correctness
- Potential memory leaks
- Race conditions
- Unnecessary allocations
- N+1 query issues

The optimized code is in: [list files]
```

## Integration with TDD

When following TDD, the Gemini review fits after the refactor phase:

```
1. Red: Write failing test
2. Green: Minimal code to pass
3. Refactor: Clean up
4. â˜… Gemini Review (if >100 lines accumulated)
5. Commit
6. Repeat
```

For multi-cycle TDD where total changes exceed threshold, call Gemini before final commit, not after each cycle.

## Handling Gemini Feedback

### Agreement
If Gemini confirms approach: proceed with implementation/commit.

### Suggestions
If Gemini suggests improvements:
1. Evaluate relevance to current scope
2. Implement critical suggestions
3. Document "nice to have" for later
4. Note in commit message if significant

### Disagreement
If Gemini disagrees with your approach:
1. Present both perspectives to user
2. Let user decide direction
3. Document reasoning in code/commit

## Failure Recovery

If Gemini invocation fails:

1. **Check syntax:** No commas in `-m` flag, `.` path correct
2. **Simplify prompt:** Remove complex formatting
3. **Retry once:** Transient failures happen
4. **Document and proceed:** If still failing, note in commit message:
   ```
   Note: Gemini review attempted but unavailable
   ```

## Pre-Commit Checklist

Before every commit, mentally check:

- [ ] New feature or architecture? â†’ Did I call Gemini BEFORE proposing?
- [ ] >100 lines changed OR >3 files with logic? â†’ Did I call Gemini AFTER implementing?
- [ ] Security code modified? â†’ Did I call Gemini for security review?
- [ ] Performance optimization? â†’ Did I call Gemini for perf review?
- [ ] <100 lines AND â‰¤3 files AND mechanical only? â†’ Skip Gemini, proceed
